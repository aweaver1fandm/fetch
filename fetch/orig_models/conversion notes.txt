The tricky(ish) part is re-using the components but with
the correct parameters.  The sizes of the inputs/outputs
differ depending on the CNN being used.  In addition, in 
tensorflow, the channel is last, but in Pytorch it's second

Below is an example of how to do the conversions for one case

https://discuss.pytorch.org/t/help-convert-tensorflow-convolutional-layer-into-pytorch/92579

Tensorflow
Conv2D(64, (3, 6), strides=(1, 1), input_shape= (10, 6, 1), activation='relu')
tf.keras.layers.Conv2D(
    filters,
    kernel_size,
    strides=(1, 1),
    padding=&#x27;valid',
    data_format=None,
    dilation_rate=(1, 1),
    groups=1,
    activation=None,
    use_bias=True,
    kernel_initializer=&#x27;glorot_uniform',
    bias_initializer=&#x27;zeros',
    kernel_regularizer=None,
    bias_regularizer=None,
    activity_regularizer=None,
    kernel_constraint=None,
    bias_constraint=None,
    **kwargs
)

Pytorch
self.conv2d = nn.Sequential(
                nn.Conv2d(1, 1, (3,6), (1, 1)),
                nn.ReLU()
              )
    Really for conv2d should be nn.Conv2d(1, 64, (3,6), (1, 1))
    In pytorch channel dimension is second not last

torch.nn.Conv2d(in_channels, 
                out_channels, 
                kernel_size, 
                stride=1, 
                padding=0, 
                dilation=1, 
                groups=1, 
                bias=True, 
                padding_mode='zeros', 
                device=None, 
                dtype=None)

For freq processing after the CNN
Densenet121 (None, 255,255,3) --> (None, 1024)
Densenet169 (None, 255,255,3) --> (None, 1664)
Densenet201 (None, 255,255,3) --> (None, 1920)
VGG19 (None, 255,255,3) --> (None, 512)

For the dm processing after the CNN
Xception (None, 255,255,3) --> (None, 2048)
VGG16 (None, 255,255,3) --> (None, 512)
InceptionV2 (None, 255,255,3) --> (None, 1536)
InceptionV3 (None, 255,255,3) --> (None, 2048)

Trying to figure out the sizes post-processing
Model A: densenet121 & Xception --> 256
Model B: densenet121 & VGG16 --> 32
Model C: densenet169 & Xception --> 112
Model D: densenet201 & Xception --> 32
Model E: vgg19 & Xception --> 128
Model F: densenet169 & VGG16 --> 512
Model G: VGG19 & VGG16 --> 128
Model H: densenet201 & InceptionV2 --> 160
Model I: densenet201 & VGG16 --> 32
Model J: VGG19 & InceptionV2 --> 512
Model K: densenet121 & InceptionV3 --> 64

For training/test data 
Need to go from 40000, 256, 256, 1 to just 40000,256, 256
      (0,0,0,0): -1.36255,
      (0,0,1,0): -0.171275,
      (0,0,2,0): -1.56031,
      (0,0,3,0): -1.58738,
      (0,0,4,0): 3.28742,
      (0,0,5,0): -1.59633,
      (0,0,6,0): 1.25719,
      (0,0,7,0): 1.22282,
      (0,0,8,0): -0.279573,
      (0,0,9,0): -1.61681,
      (0,0,10,0): 0.616355,
      (0,0,11,0): 0.127838,
      (0,0,12,0): -1.62293,
      (0,0,13,0): -0.431896,
      (0,0,14,0): 0.756318,
      (0,0,15,0): 2.60903,
      (0,0,16,0): -1.33889,
      (0,0,17,0): -0.0197761,
      (0,0,18,0): -0.130193,
      (0,0,19,0): -0.350319,
      (0,0,20,0): 1.69121,
      (0,0,21,0): -0.00435545,
      (0,0,22,0): 1.80528,
      (0,0,23,0): 1.11888,
      (0,0,24,0): 0.682746,
      (0,0,25,0): 0.932773,
      (0,0,26,0): 0.352791,
      (0,0,27,0): 0.368448,
      (0,0,28,0): 1.70428,
      (0,0,29,0): -0.865086,
      (0,0,30,0): 0.369036,
      (0,0,31,0): -0.367506,
      (0,0,32,0): -0.461442,
      (0,0,33,0): -0.263564,
      (0,0,34,0): 1.50204,
      (0,0,35,0): -0.8273,
      (0,0,36,0): 1.01506,
      (0,0,37,0): 3.89295,
      (0,0,38,0): 0.653435,
      (0,0,39,0): -1.85507,
      (0,0,40,0): -1.25566,
      (0,0,41,0): -1.13583,
      (0,0,42,0): 2.05648,
      (0,0,43,0): 0.527716,
      (0,0,44,0): -0.196937,
      (0,0,45,0): 0.783863,
      (0,0,46,0): 1.21152,
      (0,0,47,0): 1.44059,
      (0,0,48,0): -2.33723,
      (0,0,49,0): 2.85564,
      (0,0,50,0): -0.442961,
      (0,0,51,0): -0.402467,
      (0,0,52,0): 0.273687,
      (0,0,53,0): -0.83966,
      (0,0,54,0): 1.07203,
      (0,0,55,0): 1.23047,
      (0,0,56,0): -1.10005,
      (0,0,57,0): -1.10864,
      (0,0,58,0): 0.235077,
      (0,0,59,0): -0.206825,
      (0,0,60,0): 1.14725,
      (0,0,61,0): 0.0296641,
      (0,0,62,0): 1.14136,
      (0,0,63,0): -0.406234,
      (0,0,64,0): -0.0924062,
      (0,0,65,0): -0.362562,
      (0,0,66,0): -0.733481,
      (0,0,67,0): -0.840955,
      (0,0,68,0): -1.2074,
